---
title: "Sampling Statistics and Model Training in R"
author: "Kate Becker"
date: "2024-09-09"
output: html_document
---

## General Terms 
Population:  entire collection (or universe) of things under consideration 
Sample: a portion of the population we select for the analysis 

ex: polling data is an example of sampling and is gathered by asking questions of people for specific deomographics 
- the polling data can only be a subset of the general population of a country becauase it would be imposible to poll every single person, if we have a country of 300 million people and only 10 million answered the poll this is sampling 
- to fully understand what everyone in the country prefers we might have to do some extrapolation from the sample to the population 
- in the world of statistics we have values assocaited with the total population adn those associated with smaller populations 

Values related to the terms: mean, variance, and standard deviation in terms of the whole population these are called *parameters* but when talk about these but for a certain subset of the data they're *statistics*
- So we might be looking at a specific subset of a country and look at the mean statistics in that case comparing is to the mean parameter 
- the number of people in a counry who like blue would be a parameter but number of people in a particular city would be a statistic 

Bias
- sampling biase iswhat happens when you sample data in such a way that distirbutions in the samples of the data dont match up from the populations in which youre drawing from 
- sample variation is the extent to which a sample statistic (maybe favorite food as opposed to color) differs from the population 
- both of these can be controlled by picking the right way of sampling our data 


## Low bias, low variance: The best case scenario, samples are pretty well representative of the population (points are clustered and on target)

## High bias, low variance: the samples are consistent but not reflective of the entire population (points are clustered together but not on target)

## Low bias, high variance : the sample veary wildy in their consistency but some might be representative of the population (points arent clustered and are very scattered)

## High bias, high variance: the samples are a little more consistent but not likely to be representative of the entire population (points arent as clustered and arent on target)

*low bias (samples are pretty representative) low variance: samples are consistent 

#1. 
A *simple random sample* is one way of controlling bias when pulling samples from a population statement
- this is when you select values from your data at random such that every row has an equal chance of being selected 
- applying a simple random sample to the same data twice will have possibility of selecting the same data, if its truly random 

#2
A *stratified random sample* or oversampling is when you separate the data into mutually exlusive groups, called strata, and then do a simple random sample on each stratum and this would belike polling randomly across each state 
- the two advantages: 
  - ensurs representation in each strata 
  - can be more accurate than a simple random sample if there is mroe variation in one strata than others 

When you randomly select from various strata in your data (a strata could be a grouping or cut in the data that separates one part of it from another which could be due to classification or factor variables in the data)  
  
#3
The samples are spread geographically or spatially and you could perform a *cluster* sample, for examples when you have data that is stratified by country or city and this is similar to performing a stratified random sample but **picking the entire strata randomly** instead of doing a simpler random **sample within the strata**

When you take all data points from a given class or cut in the data, where the classes or cuts themselves are randomly selected

#4
A *systematic sample* is when you randomly select from your first n data points, and then select every nth data point thereafter,, this isnt random (other than the initial randomization to find the seed on which to iterate) but easy to perform on databases 


**In almost all cases you will use a simple random sample for speed and ease in implementation however certain cases may require you to stratify the data first before sampling or if data is arranged in such a way like being distributed over geographic regions you may prefer clustering 
**Note: taking 100% of your population for data isnt the best approach but need to strike a balane so that your sample has enough data points to be statistically significant and well represenative of the population statistics you're looking at 

# Sampling in R :
## Simple
```{r}
iris.df <- data.frame(iris)
sample.index <- sample(1:nrow(iris.df), nrow(iris) * 0.75, replace = FALSE)
head(iris[sample.index,])

# This code does a simple random saple of the iris dataset by first generating indices by which you need to subset your dataset and in this case we randomly select 5 rows without replacement 
# If selected replace = TRUE, when you randomly draw out a row from the data, you have the change of drawing the same row again 
```
## Stratified 
```{r}
summary(iris)
# Petal length has the highest value of variance follwed by sepal.length 
```
This sample takes 75% sample of the original data, and you can see that the distributions are all pretty close to what the population values are 
```{r}
# We intend to get a sample that has roughly the same distribution of values for any of these features but some of these columns vary to a high degree than others 

summary(iris[sample.index,])

```
```{r}
# can use the stratified functio but not available with my version of R 
library(dplyr)
library(rsample)
set.seed(123)
strata <- initial_split(iris, prop = 0.7, strata = "Sepal.Length")

train_data <- training(strata)
test_data <- testing(strata)

# View the first few rows of the training data
head(train_data)

summary(train_data)
# The stratifed sample has just about the same value
```

```{r}
# but you can you can specify which particular strata that I want to sample over, if youre sampling over many strata you generally want to start with the features that vary the least and then work way upward 
# those with the lowest variance include sepal.width and sepal.length


# again, should use stratifed function but not compatible with my R
iris <- iris %>%
  mutate(Combined_Strata = paste(Sepal.Width, Petal.Width, sep = "_"))

# Perform stratified random sampling using the combined strata
set.seed(123) # Set seed for reproducibility

split <- initial_split(iris, prop = 0.7, strata = Combined_Strata)

# Extract training (70%) and testing (30%) datasets
train_data <- training(split)
test_data <- testing(split)

# View the first few rows of the training data
head(train_data)

summary(train_data)


```

The means and variances returned here look pretty close to the population data!

# Systematic Sampling
## You can write a function that selects every nth row sequentially given some random intialization number 

```{r}
sys.saample = function(N, n) { # define function named sys.sample that takes the arguments N: total population size and n: desired sample size 
  k = ceiling(N/n) # (calculates the interval length) k, which is the step size for systematic sampling, k is computed as the ceiling of the ratio of the population size (N) to the sample size (n), using ceiling() ensures that k is rounded to the nearest whole number which avoids skipping elements when N isnt perfectly divisible by n  
  r = sample(1:k,1) # (random start point) randomly selects a starting point r from the first k element, this picks one random integer from the sequence 1 to k, setting the random start within the first interval  
  sys.sample = seq(r, r + k *(n-1), k) # generates sample sequence using the starting point r, interval length k, and sample size n , seq(r, r+k*(n-1), k) creates a sequence starting a r ending at r + k * (n-1) with a step size of k
} # the sequence selects every kth element starting from r, resulting in a sample of size n 

# ceiling takes a singe numeric argument x and returns a numeric vector containing the smallest integers not less than corresponding elements of x 
```

Example Usage:
If you call sys.sample(100, 10), assuming N = 100 and n = 10:

k = ceiling(100/10) = 10
Suppose r = 3 is randomly selected.
The systematic sample sequence would be: seq(3, 3 + 10 * (10-1), 10), which evaluates to seq(3, 93, 10), resulting in [3, 13, 23, 33, 43, 53, 63, 73, 83, 93].



#Example Usage:
If you call 
sys.sample(100, 10) #assuming N = 100 and n = 10:

k = ceiling(100/10) = 10
Suppose r = 3 is randomly selected.
The systematic sample sequence would be: seq(3, 3 + 10 * (10-1), 10), which evaluates to seq(3, 93, 10), resulting in [3, 13, 23, 33, 43, 53, 63, 73, 83, 93].

# Training and testing 
When building a predictive model you need to see what the errors generated by the model are so that you can tune it appropriately 

## Two major assumptions when working with training/testing splits 
- The data is a fair representation of the actual processes that you want to model (the subset accurately reflects the population)
- The process that you want to model are relatively stable over time and that a model built with last months data should accurately reflect next months data 

## Roles of Training and Testing Sets
- Almost all unsupervised learning algorithms follow the format for splitting the data into a training and testing set and use the training set for model training 
  - The coefficients you get as a result of the modeling procedures are based entirely on thet training data and dont depend on the testing at all 

## Why make a test set?
- The valule of making a test set of data for modelling purposes is extremely important because if it worked well for training but crashed with testing it loses all of its predictive power and becomes nothing more than a statc report 
  - "must tweek parameter B by a small amout to fit it"
  
- *Classification and regressiont regression trees (CARTS)* can be so flexibile in their modelling capabilities that if the tree is large enough you can often get misleading predictions 
  - you might train a model and see that it gives you 100% accuracy which should cause of concern , you can use the test data to evaluate the predictive performance of the trees in the data to find the one with the lowest error 
*the test set acts not only to validate the data but as a way to select which form of the model you need depending on the algorithm at play* 


## Training and Test Sets: Regression Modelling 

```{r}
set.seed(123)
x <- rnorm(100,2,1) #generate random normal data , 100 random numbers from a normal distribution with a mean of 2 and sd of 1. variable x is assigned this vector of random numbers 
y = exp(x) + rnorm(5, 0, 2) # creates a response variable y using a transformation of x , exp(x) calculates the exponential of each value in x, transforming it non-linearly 
plot(x,y)

linear <- lm(y~x) #fitting the linear regression model 
abline(a = coef(linear[1], b = coef(linear[2], lty = 2))) # adding regression line using the intercept and slope from the linear model, lty sets type of line to dashed  

# randomized data with a linear fit attached, the linear fit comes close to fitting some data points but not all (the further you extend x out, the more likely it is that your linear fit wont approximate the data very well )


```
```{r}
summary(linear)
```

The above summary uses 100% of the simulated data as its training and looks at model performance, a R squared of 0.74 isnt great but lets try to split 70/30!

```{r}
data <- data.frame(x,y)
data.samples <- sample(1:nrow(data), nrow(data) * .70, replace = FALSE)

training.data <- data[data.samples,] #training everything in 70%
test.data <- data[-data.samples,] #testing everything in 30%
```

```{r}
train.linear <- lm(y ~ x, training.data) # running the linear regression on training
```

```{r}
train.output <- predict(train.linear, test.data) # predict the linear model on test data
```
 Here your model is comparing what the model thinks the answer should be given input x compared to the actual values in your test set given by y..for regression...depending on the data and waht kind of error analysis that you want to do specifically...use **root-mean-square error (RMSE)**
 
 
